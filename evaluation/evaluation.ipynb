{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.41.2 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (4.41.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch==2.4.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: scikit-learn==1.5.1 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas==2.2.2 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from transformers==4.41.2) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from torch==2.4.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from torch==2.4.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from torch==2.4.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from torch==2.4.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from torch==2.4.0) (2024.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from scikit-learn==1.5.1) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from scikit-learn==1.5.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from scikit-learn==1.5.1) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from pandas==2.2.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from pandas==2.2.2) (2024.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from sentence-transformers==2.2.2) (0.19.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers==4.41.2) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from jinja2->torch==2.4.0) (2.1.5)\n",
      "Requirement already satisfied: click in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from requests->transformers==4.41.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from requests->transformers==4.41.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from requests->transformers==4.41.2) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from requests->transformers==4.41.2) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\barrettfrewa\\jupyter notebooks\\abfllmchatbot\\llm\\.venv\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "%pip install transformers==4.41.2 torch==2.4.0 scikit-learn==1.5.1 pandas==2.2.2 sentence-transformers==2.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'Translate English to French: How are you?',\n",
       "  'ground_truth': 'Comment Ã§a va?'},\n",
       " {'prompt': 'Translate English to French: What is your name?',\n",
       "  'ground_truth': \"Comment tu t'appelles?\"},\n",
       " {'prompt': 'Translate English to French: Good morning',\n",
       "  'ground_truth': 'Bonjour'},\n",
       " {'prompt': 'Translate English to French: Good night',\n",
       "  'ground_truth': 'Bonne nuit'},\n",
       " {'prompt': 'Translate English to French: Thank you', 'ground_truth': 'Merci'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open('translation_evaluation_data.json', 'r') as file:\n",
    "    evaluation_data = json.load(file)\n",
    "\n",
    "# Display the first 5 entries to verify data\n",
    "evaluation_data[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\BarrettFrewA\\AppData\\Local\\Temp\\ipykernel_4240\\2760224406.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  quantized_state_dict = torch.load(quantized_model_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 16)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Load the quantized model and tokenizer\n",
    "model_dir = \"t5-large\"  # Ensure this matches the model you're using\n",
    "quantized_model_path = \"../backend/quantized_t5_large.pth\"  # Update with the correct path\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# Initialize the model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "\n",
    "# Load the quantized state dictionary\n",
    "quantized_state_dict = torch.load(quantized_model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(quantized_state_dict, strict=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate translations using the model\n",
    "for item in evaluation_data:\n",
    "    input_text = item[\"prompt\"]\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    # Generate the translation\n",
    "    outputs = model.generate(input_ids, max_new_tokens=250, num_beams=5, early_stopping=True)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    \n",
    "    # Store the generated text\n",
    "    item[\"generated_text\"] = generated_text\n",
    "\n",
    "# Convert the data to a DataFrame for easier manipulation\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(evaluation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a468705b046d44dfa0dbbfb091a69e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BarrettFrewA\\Jupyter Notebooks\\ABFLLMchatbot\\LLM\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\BarrettFrewA\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cac79a423364be0a1f1c89744a70d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbe11cc89934bdf96ac790dbcbe1e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03dc4c7fb85642a5a2c0b0b2247068a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8423270a2fa0474d832cc0328a71506f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103730b65922413b8ffec8e548c3f704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load a pre-trained model for embeddings (e.g., sentence transformers)\n",
    "embedding_model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "\n",
    "def get_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Calculate cosine similarity for each pair of ground truth and generated translation\n",
    "cosine_scores = []\n",
    "for item in evaluation_data:\n",
    "    ground_truth_embedding = get_embedding(item[\"ground_truth\"], embedding_model, embedding_tokenizer)\n",
    "    generated_embedding = get_embedding(item[\"generated_text\"], embedding_model, embedding_tokenizer)\n",
    "    \n",
    "    score = cosine_similarity([ground_truth_embedding], [generated_embedding])[0][0]\n",
    "    item[\"cosine_similarity\"] = score\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(evaluation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Average Cosine Similarity: 0.7984\n",
      "Data saved as evaluation_results.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translate English to French: How are you?</td>\n",
       "      <td>Comment Ã§a va?</td>\n",
       "      <td>Comment en êtes-vous?</td>\n",
       "      <td>0.536611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Translate English to French: What is your name?</td>\n",
       "      <td>Comment tu t'appelles?</td>\n",
       "      <td>Quel est votre nom?</td>\n",
       "      <td>0.435010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Translate English to French: Good morning</td>\n",
       "      <td>Bonjour</td>\n",
       "      <td>Bonjour</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Translate English to French: Good night</td>\n",
       "      <td>Bonne nuit</td>\n",
       "      <td>Bonne nuit</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Translate English to French: Thank you</td>\n",
       "      <td>Merci</td>\n",
       "      <td>Merci.</td>\n",
       "      <td>0.973977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Translate English to French: I would like to b...</td>\n",
       "      <td>Je voudrais acheter Ã§a</td>\n",
       "      <td>J'aimerais acheter</td>\n",
       "      <td>0.266523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Translate English to French: Can you help me w...</td>\n",
       "      <td>Pouvez-vous m'aider avec mes bagages?</td>\n",
       "      <td>Pouvez-vous m'aider avec mes bagages?</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Translate English to French: I would like to c...</td>\n",
       "      <td>Je voudrais m'enregistrer</td>\n",
       "      <td>J'aimerais m'inscrire</td>\n",
       "      <td>0.340102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Translate English to French: What time does th...</td>\n",
       "      <td>Ã€ quelle heure part le train?</td>\n",
       "      <td>quelle heure le train part-il?</td>\n",
       "      <td>0.863919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Translate English to French: Where is the info...</td>\n",
       "      <td>OÃ¹ est le bureau d'information?</td>\n",
       "      <td>Où est le bureau d'information?</td>\n",
       "      <td>0.909880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0           Translate English to French: How are you?   \n",
       "1     Translate English to French: What is your name?   \n",
       "2           Translate English to French: Good morning   \n",
       "3             Translate English to French: Good night   \n",
       "4              Translate English to French: Thank you   \n",
       "..                                                ...   \n",
       "91  Translate English to French: I would like to b...   \n",
       "92  Translate English to French: Can you help me w...   \n",
       "93  Translate English to French: I would like to c...   \n",
       "94  Translate English to French: What time does th...   \n",
       "95  Translate English to French: Where is the info...   \n",
       "\n",
       "                             ground_truth  \\\n",
       "0                         Comment Ã§a va?   \n",
       "1                  Comment tu t'appelles?   \n",
       "2                                 Bonjour   \n",
       "3                              Bonne nuit   \n",
       "4                                   Merci   \n",
       "..                                    ...   \n",
       "91                Je voudrais acheter Ã§a   \n",
       "92  Pouvez-vous m'aider avec mes bagages?   \n",
       "93              Je voudrais m'enregistrer   \n",
       "94         Ã€ quelle heure part le train?   \n",
       "95       OÃ¹ est le bureau d'information?   \n",
       "\n",
       "                           generated_text  cosine_similarity  \n",
       "0                   Comment en êtes-vous?           0.536611  \n",
       "1                     Quel est votre nom?           0.435010  \n",
       "2                                 Bonjour           1.000000  \n",
       "3                              Bonne nuit           1.000000  \n",
       "4                                  Merci.           0.973977  \n",
       "..                                    ...                ...  \n",
       "91                     J'aimerais acheter           0.266523  \n",
       "92  Pouvez-vous m'aider avec mes bagages?           1.000000  \n",
       "93                  J'aimerais m'inscrire           0.340102  \n",
       "94         quelle heure le train part-il?           0.863919  \n",
       "95        Où est le bureau d'information?           0.909880  \n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you've already run the previous cells where you calculated cosine similarity and created the DataFrame `df`.\n",
    "# Calculate average cosine similarity\n",
    "average_cosine_similarity = df[\"cosine_similarity\"].mean()\n",
    "print(f\"Average Cosine Similarity: {average_cosine_similarity:.4f}\")\n",
    "\n",
    "# Save as Excel\n",
    "df.to_excel('evaluation_results.xlsx', index=False)\n",
    "print(\"Data saved as evaluation_results.xlsx\")\n",
    "\n",
    "df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
